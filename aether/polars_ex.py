from IPython.display import display, Markdown

import polars as pl
import altair as alt
import matplotlib.pyplot as plt

import types
from typing import Sequence, Optional, Union

from tqdm import tqdm


alt.themes.enable('dark')
plt.style.use('dark_background')


"""
â˜…read_csv_or_parqueté–¢æ•° â€»csvã‚’parquetã«ã—ã¨ã„ã¦æ¬¡ã‹ã‚‰æ—©ãèª­ã‚€è‡ªä½œé–¢æ•°
"""
def read_csv_or_parquet(csv_path: str, **kwargs) -> pl.DataFrame:
    """
    CSVã¾ãŸã¯å¯¾å¿œã™ã‚‹Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€Polarsã®DataFrameã‚’è¿”ã™ã€‚

    - Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’å„ªå…ˆã—ã¦èª­ã¿è¾¼ã‚€ï¼ˆé«˜é€Ÿï¼‰
    - Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°CSVã‚’èª­ã¿è¾¼ã¿ã€Parquetã¨ã—ã¦ä¿å­˜

    Parameters
    ----------
    csv_path : str
        èª­ã¿è¾¼ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns
    -------
    pl.DataFrame
        èª­ã¿è¾¼ã¾ã‚ŒãŸPolarsã®DataFrame
    """
    import os


    # æ‹¡å¼µå­ã‚’.parquetã«å·®ã—æ›¿ãˆã‚‹
    base, _ = os.path.splitext(csv_path)
    parquet_path = base + ".parquet"

    if os.path.exists(parquet_path):
        df = pl.read_parquet(parquet_path)
    else:
        df = pl.read_csv(csv_path, **kwargs)
        df.write_parquet(parquet_path)

    return df


"""
â—†_format_sigé–¢æ•°
"""
def _format_sig(x: float, sig_digits: int) -> str:
    """
    æ•°å€¤ `x` ã‚’æŒ‡å®šã•ã‚ŒãŸæœ‰åŠ¹æ•°å­—ã‚„æ¡æ•°ã§æ–‡å­—åˆ—ã¨ã—ã¦æ•´å½¢ã™ã‚‹ã€‚
    
    - None â†’ ç©ºæ–‡å­—åˆ—
    - float ã‹ã¤ int ã¨ç­‰ã—ã‘ã‚Œã°æ•´æ•°æ–‡å­—åˆ—ï¼ˆä¾‹: 5.0 â†’ '5'ï¼‰
    - ãã‚Œä»¥å¤–ã¯ 'g' ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæœ‰åŠ¹æ•°å­—ï¼‰ã‚’ä½¿ã„ã¤ã¤ã€
      æŒ‡æ•°è¡¨è¨˜ãŒå‡ºãŸå ´åˆã¯ 'f' ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¦å›ºå®šå°æ•°ç‚¹è¡¨ç¤º
    - ä¸è¦ãªå°æ•°ç‚¹ãƒ»æœ«å°¾ã‚¼ãƒ­ã‚’é™¤å»
    """
    if x is None:
        return ""
    if isinstance(x, float):
        if x == int(x):
            return str(int(x))
        s = f"{x:.{sig_digits}g}"
        if "e" in s or "E" in s:
            s = f"{x:.{sig_digits}f}"
        s = s.rstrip("0").rstrip(".") if "." in s else s
        return s
    return str(x)


"""
â˜…describe_exé–¢æ•°
"""
def describe_ex(df: pl.DataFrame, detailed: bool = True, sig_digits: int = 2) -> pl.DataFrame:
    """
    Polars DataFrame ã«å¯¾ã—ã¦æ‹¡å¼µçµ±è¨ˆè¦ç´„ã‚’è¡Œã†é–¢æ•°ã€‚

    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® `df.describe()` ã«åŠ ãˆã€ä»¥ä¸‹ã®æƒ…å ±ã‚‚è¡¨ç¤ºã™ã‚‹ï¼š
    - æ¬ ææ•°ï¼ˆmissingï¼‰ã€éæ¬ ææ•°ï¼ˆnon-missingï¼‰
    - å¹³å‡ã€æ¨™æº–åå·®ã€ä¸­å¤®å€¤ã€æœ€é »å€¤ï¼ˆtopï¼‰ã¨ãã®ä»¶æ•°ï¼ˆtop_countï¼‰
    - ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°ï¼ˆn_uniqueï¼‰
    - ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆdtypeï¼‰

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    df : pl.DataFrame
        å¯¾è±¡ã® Polars ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚

    detailed : bool, optional
        True ã®å ´åˆã€å…¨çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›ã€‚False ã¾ãŸã¯ None ã®å ´åˆã€`df.describe()` ç›¸å½“ã®å‡ºåŠ›ã‚’æ•´å½¢ã—ã¦è¿”ã™ã€‚
        None ã®ã¨ãã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° `detailed` ã‚’å‚ç…§ï¼ˆæœªå®šç¾©æ™‚ã¯ False æ‰±ã„ï¼‰ã€‚

    sig_digits : int, optional (default=2)
        æ•°å€¤ã®æœ‰åŠ¹æ¡æ•°ã€‚None ã®å ´åˆã¯ä¸¸ã‚å‡¦ç†ã‚’è¡Œã‚ãªã„ã€‚

    æˆ»ã‚Šå€¤
    -------
    pl.DataFrame
        çµ±è¨ˆæƒ…å ±ã‚’æ–‡å­—åˆ—å‹ã§ã¾ã¨ã‚ãŸ DataFrameã€‚å„åˆ—ã«å¯¾ã™ã‚‹çµ±è¨ˆå€¤ã‚’è¡Œæ–¹å‘ã«è¡¨ç¤ºã€‚

    ä½¿ç”¨ä¾‹
    -------
    >>> import polars as pl
    >>> df = pl.DataFrame({"x": [1, 2, 2, None], "y": ["a", "b", "a", "a"]})
    >>> describe_ex(df, detailed=True)

    å‚™è€ƒ
    ----
    - detailed=False ã®å ´åˆã€`pl.DataFrame.describe()` ã«è¿‘ã„å½¢å¼ï¼ˆæ•´å½¢æ¸ˆï¼‰ã‚’è¿”ã™ã€‚
    - éæ•°å€¤åˆ—ï¼ˆæ–‡å­—åˆ—ãªã©ï¼‰ã§ã‚‚ top ã‚„ãƒ¦ãƒ‹ãƒ¼ã‚¯ä»¶æ•°ãªã©ã‚’é›†è¨ˆå¯èƒ½ã€‚
    - å‹æƒ…å ±ã‚„æ¬ æçŠ¶æ³ãªã©ã‚‚ä¸€ç·’ã«ç¢ºèªã—ãŸã„å ´åˆã«ä¾¿åˆ©ã€‚
    """
    # if detailed is None:
    #     detailed = globals().get("detailed", False)

    describe_schema = df.schema

    if not detailed:
        df_simple = df.describe(percentiles=[0.5])
        if sig_digits is not None:
            df_simple = df_simple.with_columns([
                pl.col(col)
                .map_elements(lambda x: _format_sig(x, sig_digits), return_dtype=pl.String)
                .alias(col)
                for col in df_simple.columns if col != "statistic"
            ])
        return df_simple.cast(pl.Utf8)

    # === çµ±è¨ˆè¡Œã®åé›† ===
    stat_labels = [
        ("non-missing", lambda s: s.len()),
        ("missing", lambda s: s.null_count()),
        ("mean", lambda s: s.mean()),
        ("std", lambda s: s.std()),
        ("min", lambda s: s.min()),
        ("median", lambda s: s.median()),
        ("max", lambda s: s.max()),
    ]

    stats_rows = []
    for label, func in stat_labels:
        row = {"statistic": label}
        for col in df.columns:
            try:
                val = df.select(func(pl.col(col)))[0, 0]
                row[col] = _format_sig(val, sig_digits)
            except:
                row[col] = ""
        stats_rows.append(row)

    # === è£œè¶³çµ±è¨ˆï¼ˆdtype, top, top_count, n_uniqueï¼‰ ===
    stats_df = df.select([
        pl.col(col).n_unique().alias(f"{col}_n_unique") for col in df.columns
    ]).to_dict(as_series=False)

    rows = {
        "dtype": {"statistic": "dtype"},
        "top": {"statistic": "top"},
        "top_count": {"statistic": "top_count"},
        "n_unique": {"statistic": "n_unique"},
    }

    for col in df.columns:
        dtype = describe_schema[col]
        n_val = stats_df[f"{col}_n_unique"][0]
        assert isinstance(n_val, (int, float)), f"n_unique for column '{col}' must be numeric"

        try:
            top_row = (
                df.select(pl.col(col))
                .group_by(col)
                .agg(pl.len().alias("count"))
                .sort("count", descending=True)
                .limit(1)
            )
            top_val = top_row[0, col] if top_row.height > 0 else None
            top_count = top_row[0, "count"] if top_row.height > 0 else 0
        except:
            top_val = None
            top_count = None

        rows["dtype"][col] = str(dtype)
        rows["top"][col] = _format_sig(top_val, sig_digits)
        rows["top_count"][col] = str(top_count)
        rows["n_unique"][col] = str(int(n_val))

    extra_rows = [rows[k] for k in ["dtype", "top", "top_count", "n_unique"]]
    df_result = pl.DataFrame(stats_rows + extra_rows).cast(pl.Utf8)

    # è¡Œã®ä¸¦ã³æ›¿ãˆ
    desired_order = [
        "dtype", "non-missing", "missing", "n_unique",
        "mean", "std", "min", "median", "max", "top", "top_count"
    ]
    actual_stats = df_result.select("statistic").to_series().to_list()
    sorted_stats = [s for s in desired_order if s in actual_stats] + [s for s in actual_stats if s not in desired_order]

    df_result = df_result.with_columns(
        pl.col("statistic").map_elements(lambda s: sorted_stats.index(s), return_dtype=pl.Int32).alias("__sort_order")
    ).sort("__sort_order").drop("__sort_order")

    return df_result

# Monkey patchï¼ˆä»»æ„ï¼‰
pl.DataFrame.describe_ex = describe_ex


"""
â˜…get_bin_columnsé–¢æ•°
"""
def get_bin_column(
    *dfs: pl.DataFrame,
    col: str,
    num_n_bins: int = 10,
    num_sig_digits: int = 3,
    dt_truncate_unit: str = "1mo",
    verbose:bool = False
) -> tuple[pl.DataFrame, pl.DataFrame]:
    """
    æŒ‡å®šåˆ—ã«å¯¾ã—ã¦ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆbinåˆ—ã®è¿½åŠ ï¼‰ã‚’è¡Œã„ã€å„DataFrameã«å¯¾å¿œã™ã‚‹binåˆ—ã¨binæƒ…å ±ã‚’è¿”ã™é–¢æ•°ã€‚

    æ•°å€¤ãƒ»æ—¥æ™‚ãƒ»ã‚«ãƒ†ã‚´ãƒªå‹ã«å¯¾å¿œã—ã€ãƒ“ãƒ‹ãƒ³ã‚°ã®æ–¹æ³•ã‚’è‡ªå‹•çš„ã«åˆ¤åˆ¥ã™ã‚‹ã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    *dfs : pl.DataFrame
        å‡¦ç†å¯¾è±¡ã®è¤‡æ•°ã® Polars DataFrameã€‚å¯¾è±¡åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘ã‚’å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹ã€‚

    col : str
        ãƒ“ãƒ‹ãƒ³ã‚°å¯¾è±¡ã®åˆ—åã€‚

    num_n_bins : int, optional (default=10)
        æ•°å€¤åˆ—ã®ã¨ãã«ä½œæˆã™ã‚‹ãƒ“ãƒ³ã®æœ€å¤§æ•°ã€‚`matplotlib.ticker.MaxNLocator` ã‚’ç”¨ã„ã¦è‡ªå‹•ã§åŒºåˆ‡ã‚‹ã€‚

    num_sig_digits : int, optional (default=3)
        æ•°å€¤åˆ—ã®ãƒ“ãƒ³å¢ƒç•Œå€¤ã‚’æœ‰åŠ¹æ•°å­—ã§ä¸¸ã‚ã‚‹æ¡æ•°ã€‚

    dt_truncate_unit : str, optional (default="1mo")
        æ—¥ä»˜ãƒ»æ—¥æ™‚åˆ—ã«å¯¾ã—ã¦ `.dt.truncate()` ã™ã‚‹éš›ã®å˜ä½ï¼ˆä¾‹: "1mo", "1d" ãªã©ï¼‰ã€‚

    verbose : bool, optional (default=False)
        ä¸­é–“å‡¦ç†ã®è¡¨ç¤ºã‚’è¡Œã†ï¼ˆJupyterãªã©ã§ `display()` ã‚’ä½¿ç”¨ï¼‰ã€‚

    æˆ»ã‚Šå€¤
    -------
    tuple[pl.DataFrame, ..., pl.DataFrame]
        - å„å…¥åŠ› DataFrame ã«å¯¾å¿œã™ã‚‹ bin åˆ—ã ã‘ã‚’æŒã¤ DataFrame ã®ã‚¿ãƒ—ãƒ«ï¼ˆå…¥åŠ›ã®é †ã«ä¸¦ã¶ï¼‰ã€‚
        - æœ€å¾Œã®è¦ç´ ã¯ bin ã®è©³ç´°æƒ…å ±ï¼ˆé–‹å§‹ã€çµ‚äº†ã€ä¸­å¤®å€¤ãªã©ï¼‰ã‚’æŒã¤ DataFrameï¼ˆæ•°å€¤ãƒ»æ—¥ä»˜åˆ—ã®ã¨ãã®ã¿ï¼‰ã€‚

    ä½¿ç”¨ä¾‹
    -------
    >>> df1 = pl.DataFrame({"val": [1, 2, 3, 4, 5]})
    >>> df2 = pl.DataFrame({"val": [6, 7, 8, 9, 10]})
    >>> df1_bin, df2_bin, df_bin_info = get_bin_column(df1, df2, col="val")

    å‚™è€ƒ
    ----
    - æ•°å€¤åˆ—ã®å ´åˆï¼šç­‰é–“éš”ãƒ“ãƒ³ã«åˆ†å‰²ã—ã€`cut` ã«ã‚ˆã£ã¦ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ãŸã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’ç”Ÿæˆã€‚
    - æ—¥ä»˜ãƒ»æ—¥æ™‚åˆ—ã®å ´åˆï¼š`dt.truncate()` ã«ã‚ˆã‚ŠæœŸé–“å˜ä½ã§ãƒ“ãƒ³ã‚’ä½œæˆã€‚
    - æ–‡å­—åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ—ã®å ´åˆï¼šå…ƒã®å€¤ã‚’ãã®ã¾ã¾ bin ã¨ã—ã¦åˆ©ç”¨ã€‚
    - å…ƒã®åˆ—ãŒå­˜åœ¨ã—ãªã„ DataFrame ã«å¯¾ã—ã¦ã¯ã€ã™ã¹ã¦ `None` ã® bin åˆ—ã‚’è¿”ã™ã€‚
    - binè©³ç´°ï¼ˆ`_start`, `_end`, `_median`ï¼‰ã¯æœ€çµ‚è¿”å´è¦ç´ ã«æ ¼ç´ã€‚
    """
    import matplotlib.ticker as mticker


    col_bin = col + '_bin'
    # # æœ€åˆã®dfã‹ã‚‰å‹ã‚’å–å¾—ï¼ˆã‚¢ã‚µãƒ¼ãƒˆè¾¼ã¿ï¼‰
    # assert all(col in df.columns for df in dfs), f"åˆ— `{col}` ãŒå­˜åœ¨ã—ãªã„DataFrameãŒã‚ã‚Šã¾ã™"
    # dtype = dfs[0].schema[col]
    # assert all(df.schema[col] == dtype for df in dfs), f"`{col}` ã®å‹ãŒDataFrameé–“ã§ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“"
    # df_concat = pl.concat([df.select(col) for df in dfs])
    # colã‚’æŒã£ã¦ã„ã‚‹DataFrameã®ã¿æŠ½å‡º
    dfs_with_col = [df for df in dfs if col in df.columns]
    if not dfs_with_col:
        raise ValueError(f"æŒ‡å®šã•ã‚ŒãŸåˆ— `{col}` ã‚’æŒã¤DataFrameãŒ1ã¤ã‚‚ã‚ã‚Šã¾ã›ã‚“")
    # æœ€åˆã«colã‚’æŒã£ã¦ã„ã‚‹dfã‹ã‚‰å‹å–å¾—ï¼ˆå‹ä¸ä¸€è‡´ã‚¢ã‚µãƒ¼ãƒˆã¯çœç•¥å¯ï¼‰
    dtype = dfs_with_col[0].schema[col]
    # min/max ã‚’å–ã‚‹ãŸã‚ã®çµåˆç”¨
    df_concat = pl.concat([df.select(col) for df in dfs_with_col])

    if dtype in (pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64, pl.Float32, pl.Float64):
        min_val = df_concat.select(col).to_series().min()
        max_val = df_concat.select(col).to_series().max()
        locator = mticker.MaxNLocator(nbins=num_n_bins)
        bins = locator.tick_values(min_val, max_val)
        if verbose:
            print("bins(mticker.MaxNLocator):")
            display(bins)
        bins = [_round_sig(bin, num_sig_digits) for bin in bins] # æœ‰åŠ¹æ•°å­—ã§ä¸¸ã‚ã‚‹
        bins = sorted(list(set(bins))) # é‡è¤‡ã‚’æ’ã™(ä¸¸ã‚ãŸå½±éŸ¿ã§ã‹ã¶ã‚ŠãŒå‡ºã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹)â‡’ä¸¦ã³ãŒå´©ã‚Œã‚‹ã®ã§ä¸¦ã¹ç›´ã™
        breaks = bins[1:-1]
        labels = _make_bin_labels(bins)
        starts = bins[:-1]
        ends = bins[1:]
        centers = [(s + e) / 2 for s, e in zip(starts, ends)]

        dfs_bin = []
        for df in dfs:
            # df_bin = df.select([
            #     pl.col(col).cut(breaks=breaks, labels=labels).alias(f"{col}_bin")
            # ])
            # dfs_bin.append(df_bin)
            if col in df.columns:
                df_bin = df.select([
                    pl.col(col).cut(breaks=breaks, labels=labels).alias(col_bin)
                ])
            else:
                # å…ƒã®åˆ—ãŒãªã„å ´åˆã€å…¨éƒ¨å€¤ãŒNullã®åˆ—ã‚’è¿”ã™
                df_bin = pl.DataFrame({col_bin: pl.Series(name=col_bin, values=[None] * df.height, dtype=dtype)})
            dfs_bin.append(df_bin)
            if verbose:
                print("df_bin:")
                display(df_bin)
            assert df.height == df_bin.height, (
                f"Row count mismatch: df={df.height}, df_bin={df_bin.height}"
            )

        df_bin_detail_info = pl.DataFrame({
            f"{col_bin}": labels,
            f"{col_bin}_start": starts,
            f"{col_bin}_end": ends,
            f"{col_bin}_median": centers
        }).with_columns([
            pl.col(f"{col}_bin").cast(pl.Categorical)
        ])
        if verbose:
            print("df_bin_detail_info:")
            display(df_bin_detail_info)

    elif dtype in (pl.Date, pl.Datetime):
        # binåˆ—ã‚’è¿½åŠ ï¼ˆtruncateå‡¦ç†ï¼‰
        dfs_bin = []
        for df in dfs:
            if col in df.columns:
                df_bin = df.select(
                    pl.col(col).dt.truncate(dt_truncate_unit).alias(f"{col}_bin")
                )
            else:
                # å…ƒã®åˆ—ãŒãªã„å ´åˆã€å…¨éƒ¨å€¤ãŒNullã®åˆ—ã‚’è¿”ã™
                df_bin = pl.DataFrame({col_bin: pl.Series(name=col_bin, values=[None] * df.height, dtype=dtype)})
            dfs_bin.append(df_bin)
            if verbose:
                print("df_bin:")
                display(df_bin)

        # æœ€å°ãƒ»æœ€å¤§æ—¥æ™‚ã‚’å–å¾—
        min_date = df_concat.select(pl.col(col).min().dt.truncate(dt_truncate_unit)).item()
        # max_date = df.select(pl.col(col).max()).item()
        max_date_plus_1_unit = df_concat.select(pl.col(col).max().dt.offset_by(dt_truncate_unit)).item()

        # é€£ç¶šã—ãŸbiné–‹å§‹ç‚¹ã®ç”Ÿæˆï¼ˆä¾‹ï¼š1æ—¥ã”ã¨ã®æœˆåˆï¼‰
        range_fn = pl.date_range if dtype == pl.Date else pl.datetime_range
        bin_starts_plus_1_unit = range_fn(
            start=min_date,
            end=max_date_plus_1_unit,
            interval=dt_truncate_unit,
            eager=True
        ) # ã‚±ãƒ„ã«1æœŸé–“ã‚’è¶³ã—ãŸãƒªã‚¹ãƒˆ

        # bin_endåˆ—ï¼ˆ1ã¤å…ˆã®startï¼‰
        bin_starts = bin_starts_plus_1_unit[:-1].to_list() # ã‚±ãƒ„ã®1æœŸé–“ã¯å‰Šã‚‹
        bin_ends = bin_starts_plus_1_unit[1:].to_list() # æœ€åˆã®1æœŸé–“ã¯å‰Šã‚‹

        bin_medians = [start + (end - start) // 2 for start, end in zip(bin_starts, bin_ends)]

        # DataFrameåŒ–
        # df_bin_detail_info = pl.DataFrame({
        #     f"{col_bin}": bin_starts,
        #     f"{col_bin}_start": bin_starts,
        #     f"{col_bin}_end": bin_ends,
        #     f"{col_bin}_median": bin_medians
        # })
        # æ™‚åˆ»ãƒ“ãƒ³è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å…ˆã«ä½œã‚‹ï¼ˆÎ¼sç²¾åº¦ï¼‰
        df_bin_detail_info = pl.DataFrame({
            f"{col_bin}": bin_starts,
            f"{col_bin}_start": bin_starts,
            f"{col_bin}_end": bin_ends,
            f"{col_bin}_median": bin_medians
        })

        # ãƒ“ãƒ³åˆ—ã®ç²¾åº¦ã‚’å–å¾—ï¼ˆ"us", "ms", etcï¼‰
        target_unit = df_bin_detail_info.schema[f"{col_bin}"].time_unit

        # å„dfã« binåˆ—ã‚’è¿½åŠ ï¼ˆtruncate & castï¼‰
        dfs_bin = []
        for df in dfs:
            if col in df.columns:
                df_bin = df.select(
                    pl.col(col).dt.truncate(dt_truncate_unit).dt.cast_time_unit(target_unit).alias(col_bin)
                )
            else:
                df_bin = pl.DataFrame({col_bin: pl.Series(name=col_bin, values=[None] * df.height, dtype=pl.Datetime("Î¼s"))})
            dfs_bin.append(df_bin)

        if verbose:
            print("df_bin_detail_info:")
            display(df_bin_detail_info)

    elif dtype in (pl.Utf8, pl.Categorical):
        dfs_bin = []
        for df in dfs:
            if col in df.columns:
                df_bin = df.select([pl.col(col).alias(f"{col_bin}")])#[f"{col}_bin"]
            else:
                # å…ƒã®åˆ—ãŒãªã„å ´åˆã€å…¨éƒ¨å€¤ãŒNullã®åˆ—ã‚’è¿”ã™
                df_bin = pl.DataFrame({col_bin: pl.Series(name=col_bin, values=[None] * df.height, dtype=dtype)})
            dfs_bin.append(df_bin)
            if verbose:
                print("df_bin:")
                display(df_bin)
        df_bin_detail_info = None

    else:
        raise ValueError(f"Unsupported dtype: {dtype}")

    return (*dfs_bin, df_bin_detail_info)


def _round_sig(x: float, sig: int) -> float:
    import math


    if x == 0:
        return 0.0
    return round(x, sig - int(math.floor(math.log10(abs(x)))) - 1)


def _make_bin_labels(bins: list[float]) -> list[str]:
    labels = [
        f"{start}â€“{end}"
        for start, end in zip(bins[:-1], bins[1:])
    ]
    return labels


"""
â˜…plot_histogramé–¢æ•°
- â†‘ã®binningé–¢æ•°ã‚’å†…éƒ¨ã§ä½¿ã£ã¦ã€ãã‚Œã‚’ä½¿ã£ã¦é›†è¨ˆã—ãŸã‚‚ã®ã‚’Histogramã«ã™ã‚‹å‡¦ç†
"""
def plot_histogram(
    df: pl.DataFrame,
    col_bin: str,
    df_bin_detail_info: pl.DataFrame = None,
    col_color: str = None,
    bar_opacity: float = 0.5,
    num_x_scale_zero: bool = False,
    normalize_histogram: bool = False,
    title: str = None,
    verbose: bool = False
) -> alt.Chart:
    """
    Altair ã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰ã‚’æç”»ã™ã‚‹é–¢æ•°ã€‚

    ãƒ“ãƒ³åˆ—ï¼ˆã‚«ãƒ†ã‚´ãƒªã€æ•°å€¤ã€ã¾ãŸã¯æ—¥ä»˜ã®ãƒ“ãƒ³ï¼‰ã‚’ã‚‚ã¨ã«é›†è¨ˆã—ã€æ£’ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚
    æ—¥ä»˜ãƒ»æ•°å€¤ãƒ“ãƒ³ã®å ´åˆã¯ `df_bin_detail_info` ã‚’æ¸¡ã™ã“ã¨ã§æ£’ã®å¹…ã‚’æ˜ç¤ºçš„ã«è¨­å®šå¯èƒ½ã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    df : pl.DataFrame
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚ãƒ“ãƒ³åˆ—ã‚’å«ã‚“ã§ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

    col_bin : str
        ãƒ“ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®åˆ—åï¼ˆ"xxx_bin" ãªã©ï¼‰ã€‚æ£’ã‚°ãƒ©ãƒ•ã®Xè»¸ã¨ãªã‚‹ã€‚

    df_bin_detail_info : pl.DataFrame, optional
        ãƒ“ãƒ³ã®è©³ç´°æƒ…å ±ï¼ˆ`_start`, `_end` åˆ—ãªã©ï¼‰ã‚’å«ã‚€DataFrameã€‚
        ã“ã‚ŒãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€Altair ã® `x` ã¨ `x2` ã‚’ç”¨ã„ã¦æ£’ã®å¹…ã‚’é€£ç¶šå€¤ã¨ã—ã¦æç”»ã™ã‚‹ã€‚

    col_color : str, optional
        ã‚°ãƒ«ãƒ¼ãƒ—æ¯ã«è‰²åˆ†ã‘ã—ãŸã„åˆ—åã€‚None ã®å ´åˆã¯è‰²åˆ†ã‘ã—ãªã„ã€‚

    bar_opacity : float, optional (default=0.5)
        æ£’ã®é€æ˜åº¦ã€‚

    num_x_scale_zero : bool, optional (default=False)
        Xè»¸ï¼ˆé€£ç¶šå€¤ï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«ã‚¼ãƒ­ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹ã€‚

    normalize_histogram : bool, optional (default=False)
        ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ç›¸å¯¾é »åº¦ï¼ˆå‰²åˆï¼‰ã¨ã—ã¦æ­£è¦åŒ–ã™ã‚‹ã‹ã©ã†ã‹ã€‚

    title : str, optional
        ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«ã€‚None ã®å ´åˆã¯ `col_bin` ã‹ã‚‰è‡ªå‹•æ¨å®šã€‚

    verbose : bool, optional
        å‡¦ç†é€”ä¸­ã®DataFrameã‚’ `display()` ã§è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€‚

    æˆ»ã‚Šå€¤
    -------
    alt.Chart
        Altair ã«ã‚ˆã‚‹æ£’ã‚°ãƒ©ãƒ•ãƒãƒ£ãƒ¼ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚

    ä½¿ç”¨ä¾‹
    -------
    >>> chart = plot_histogram(df, col_bin="age_bin", df_bin_detail_info=bin_info)
    >>> chart.display()

    å‚™è€ƒ
    ----
    - `df_bin_detail_info` ã‚’æ¸¡ã™ã¨ã€æ£’ã®å¹…ã‚„ä½ç½®ãŒé€£ç¶šçš„ã«è¡¨ç¤ºã•ã‚Œã€è¦–èªæ€§ãŒå‘ä¸Šã™ã‚‹ã€‚
    - ã‚«ãƒ†ã‚´ãƒªãƒ“ãƒ³ã®å ´åˆã¯ `x` ã®ã¿ã€é€£ç¶šãƒ“ãƒ³ã®å ´åˆã¯ `x` + `x2` ã«ã‚ˆã‚‹ãƒ¬ãƒ³ã‚¸æŒ‡å®šã‚’è¡Œã†ã€‚
    - Polars ã¨ Altair ã‚’çµ„ã¿åˆã‚ã›ã¦è»½é‡ãªå¯è¦–åŒ–ãŒå¯èƒ½ã€‚
    """    
    if verbose:
        print(f"col_bin: {col_bin}")
        print('df:')
        display(df)
    
    if title is None:
        if col_bin.endswith("_bin"):
            title = col_bin.removesuffix("_bin")
        else:
            title = col_bin

    col_y = 'count'
    group_keys = [col_bin]
    if col_color and (col_bin != col_color):
        group_keys.append(col_color)
    if normalize_histogram == False:
        expr = pl.len().alias(col_y)
    else:
        expr = (pl.len() / pl.lit(len(df))).alias(col_y)
    if verbose:
        print(f'group_keys: {group_keys}')
    df_agg = df.group_by(pl.col(group_keys)).agg(expr)
    if verbose:
        print('df_agg:')
        display(df_agg)

    if df_bin_detail_info is not None:
        if verbose:
            print('df_bin_detail_info:')
            display(df_bin_detail_info)

        df_agg = df_agg.join(df_bin_detail_info, on=col_bin, how='left')
        if verbose:
            print('df_agg(joint):')
            display(df_agg)

        col_bin_start = f"{col_bin}_start"
        col_bin_end = f"{col_bin}_end"
        assert col_bin_start in df_agg.columns, f"{col_bin_start} ãŒ df_agg ã«å­˜åœ¨ã—ã¾ã›ã‚“"
        assert col_bin_end in df_agg.columns, f"{col_bin_end} ãŒ df_agg ã«å­˜åœ¨ã—ã¾ã›ã‚“"

        df_plot = df_agg.with_columns([
            pl.col(col_bin_start).alias("bin_left"),
            pl.col(col_bin_end).alias("bin_right"),
            pl.col(col_y).alias("bin_top"),
            pl.lit(0).alias("bin_bottom")
        ])
        if verbose:
            print('df_plot:')
            display(df_plot)

        dtype = df_plot.schema["bin_left"]
        bin_type = "temporal" if dtype in (pl.Datetime, pl.Date) else "quantitative"

        chart = alt.Chart(df_plot).encode(
            x=alt.X("bin_left", type=bin_type, title=None, scale=alt.Scale(zero=num_x_scale_zero)),
            x2="bin_right",
            y=alt.Y("bin_bottom:Q", title="count"),
            y2=alt.Y2("bin_top:Q")
        )

    else:
        chart = alt.Chart(df_agg).encode(
            x=alt.X(f"{col_bin}:N", title="category"),
            y=alt.Y(f"{col_y}:Q", title="count")
        )

    chart = chart.mark_bar(opacity=bar_opacity, stroke='gray', strokeWidth=1).properties(title=title)
    if col_color:
        chart = chart.encode(color=alt.Color(f"{col_color}:N"))
    
    return chart


"""
â˜…plot_line_point_over_biné–¢æ•°
"""
def plot_line_point_over_bin(
    df: pl.DataFrame,
    col_bin: str,
    col_target: str,
    col_color: str = None,
    agg_func = pl.mean,
    df_bin_detail_info: pl.DataFrame = None,
    num_y_scale_zero: bool = False,
    point_size: int = 50,
    verbose: bool = False,
    color_scale_scheme: str = None,
) -> alt.Chart:
    """
    ãƒ“ãƒ³ã”ã¨ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’é›†ç´„ã—ã€ç·šï¼‹ç‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’ Altair ã§æç”»ã™ã‚‹é–¢æ•°ã€‚

    é›†ç´„ã•ã‚ŒãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã‚’ãƒ“ãƒ³ã®ä¸­å¤®å€¤ã¾ãŸã¯ã‚«ãƒ†ã‚´ãƒªã§Xè»¸ã«ã€ç·šã¨ç‚¹ã®é‡ã­åˆã‚ã›ã§è¦–è¦šåŒ–ã™ã‚‹ã€‚
    ã‚«ãƒ©ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã§ã®æ¯”è¼ƒã‚„ã€binæƒ…å ±ã®ä¸­é–“ç‚¹æŒ‡å®šã«ã‚‚å¯¾å¿œã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    df : pl.DataFrame
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚ãƒ“ãƒ³åˆ—ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ãƒ»ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰ã‚«ãƒ©ãƒ¼åˆ—ã‚’å«ã‚€ã€‚

    col_bin : str
        ãƒ“ãƒ‹ãƒ³ã‚°åˆ—ã®åå‰ã€‚ã‚«ãƒ†ã‚´ãƒªã¾ãŸã¯ bin æƒ…å ±ã«åŸºã¥ãåˆ—ã€‚

    col_target : str
        Yè»¸ã«ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹å¯¾è±¡åˆ—ã€‚æ•°å€¤å‹ã‚’æƒ³å®šã€‚

    col_color : str, optional
        ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ç·šãƒ»ç‚¹ã‚’è‰²åˆ†ã‘ã™ã‚‹åˆ—åã€‚None ã®å ´åˆã¯å˜ä¸€è‰²ã€‚

    agg_func : Callable, optional (default=pl.mean)
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã®é›†ç´„é–¢æ•°ï¼ˆä¾‹: `pl.mean`, `pl.median`, `pl.max` ãªã©ï¼‰ã€‚

    df_bin_detail_info : pl.DataFrame, optional
        ãƒ“ãƒ³ã®è©³ç´°æƒ…å ±ã‚’å«ã‚€ DataFrameã€‚åˆ— `{col_bin}_median` ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚’Xè»¸ã«ä½¿ç”¨ã€‚

    num_y_scale_zero : bool, optional
        Yè»¸ã‚¹ã‚±ãƒ¼ãƒ«ã« 0 ã‚’å«ã‚ã‚‹ã‹ã©ã†ã‹ï¼ˆAltair ã® `scale.zero` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚

    point_size : int, optional (default=50)
        ãƒ—ãƒ­ãƒƒãƒˆã•ã‚Œã‚‹ç‚¹ã®ã‚µã‚¤ã‚ºã€‚

    verbose : bool, optional
        å‡¦ç†ä¸­ã® DataFrame ã‚’ `display()` ã§è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€‚

    color_scale_scheme : str, optional
        Altair ã®ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ åï¼ˆä¾‹: "category10", "tableau20" ãªã©ï¼‰ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€‚

    æˆ»ã‚Šå€¤
    -------
    alt.Chart
        ç·šï¼ˆlineï¼‰ã¨ç‚¹ï¼ˆpointï¼‰ã‚’é‡ã­ãŸ Altair ã®è¤‡åˆãƒãƒ£ãƒ¼ãƒˆã€‚

    ä½¿ç”¨ä¾‹
    -------
    >>> chart = plot_line_point_over_bin(df, col_bin="age_bin", col_target="score", col_color="gender")
    >>> chart.display()

    å‚™è€ƒ
    ----
    - `df_bin_detail_info` ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¦ `{col_bin}_median` ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€Xè»¸ã«ã¯ãã®ä¸­å¤®å€¤ã‚’ä½¿ã†ã€‚
    - è‰²ã¨å½¢ã¯ `col_color` ã«ã‚ˆã£ã¦è‡ªå‹•çš„ã«å¤‰åŒ–ã—ã€å‡¡ä¾‹ã‚‚è‡ªå‹•è¡¨ç¤ºã•ã‚Œã‚‹ã€‚
    - `resolve_scale` ã«ã‚ˆã‚Š y è»¸ã¯å…±æœ‰ã•ã‚Œã€color/shape ã¯ç‹¬ç«‹ã€‚
    """
    col_target_agg = f'{col_target} ({agg_func.__name__})'

    # é›†ç´„
    group_keys = [col_bin] + ([col_color] if col_color else [])
    df_agg = df.group_by(group_keys).agg(agg_func(col_target).alias(col_target_agg))

    if df_bin_detail_info is not None:
        df_agg = df_agg.join(df_bin_detail_info, on=col_bin, how="left")

    if verbose:
        print('df_agg:')
        display(df_agg)

    col_bin_median = f"{col_bin}_median"
    col_x = col_bin_median if col_bin_median in df_agg.columns else col_bin

    if verbose:
        print(f"col_x: {col_x}, col_color: {col_color}")

    base = alt.Chart(df_agg)
    enc_x = alt.X(col_x)
    enc_y = alt.Y(f"{col_target_agg}:Q", axis=alt.Axis(orient="right"), scale=alt.Scale(zero=num_y_scale_zero))

    chart_line = base.mark_line().encode(
        x=enc_x, y=enc_y, color=alt.Color(f"{col_color}:N", legend=None, scale=alt.Scale(scheme=color_scale_scheme))
    )
    chart_point = base.mark_point(size=point_size).encode(
        x=enc_x, y=enc_y, 
        color=alt.Color(f"{col_color}:N", scale=alt.Scale(scheme=color_scale_scheme)), 
        shape=alt.Shape(f"{col_color}:N")
    )

    return alt.layer(chart_line, chart_point).resolve_scale(y='shared', color='independent', shape='independent')


def _align_all_columns(*dfs: pl.DataFrame) -> tuple[pl.DataFrame, ...]:
    if not dfs:
        raise ValueError("å°‘ãªãã¨ã‚‚1ã¤ã®DataFrameãŒå¿…è¦ã§ã™")

    # --- 1. å…¨åˆ—ã®å‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ä¸€è²«æ€§ã‚’ç¢ºèª ---
    col_types: dict[str, pl.DataType] = {}
    for df in dfs:
        for col, dtype in df.schema.items():
            if col in col_types:
                assert col_types[col] == dtype, f"åˆ— '{col}' ã®å‹ãŒä¸€è‡´ã—ã¾ã›ã‚“: {col_types[col]} â‰  {dtype}"
            else:
                col_types[col] = dtype

    # --- 2. å…¨åˆ—åã‚’åé›†ï¼ˆé †åºï¼šdf1ã®åˆ—é †ï¼‹ä»–ã«ã—ã‹ãªã„åˆ—ï¼‰ ---
    base_cols = list(dfs[0].columns)
    other_cols = [col for df in dfs[1:] for col in df.columns if col not in base_cols]
    final_col_order = base_cols + sorted(set(other_cols), key=other_cols.index)  # ä»–ã®åˆ—ã¯ç™»å ´é †

    # --- 3. å„DataFrameã«è¶³ã‚Šãªã„åˆ—ã‚’è¿½åŠ ã—ã€é †ç•ªã‚’æƒãˆã‚‹ ---
    aligned_dfs = []
    for df in dfs:
        missing_cols = [col for col in final_col_order if col not in df.columns]
        df_extended = df.with_columns(
            [pl.lit(None).cast(col_types[col]).alias(col) for col in missing_cols]
        )
        df_aligned = df_extended.select(final_col_order)
        aligned_dfs.append(df_aligned)

    return tuple(aligned_dfs)


def _standardize_columns_by_first_df(
    *dfs: pl.DataFrame,
    col_list: list[str],
    verbose: bool = False
) -> list[pl.DataFrame]:
    """
    å„åˆ—ã”ã¨ã«ã€æœ€åˆã«æœ‰åŠ¹å€¤ã‚’æŒã¤DataFrameã‚’åŸºæº–ã¨ã—ã¦æ¨™æº–åŒ–ã€‚
    å¤‰æ›å¾Œã®np.nanã¯Polarsã®Noneã«å¤‰æ›ã—ã¦è¿”ã™ã€‚
    """
    from sklearn.preprocessing import StandardScaler


    if not dfs:
        raise ValueError("å°‘ãªãã¨ã‚‚1ã¤ã®DataFrameãŒå¿…è¦ã§ã™")

    if verbose:
        print(">>> æ¨™æº–åŒ–å¯¾è±¡ã®åˆ—:", col_list)
        print(">>> å…¥åŠ›DataFrameã®æ•°:", len(dfs))

    # å„åˆ—ã”ã¨ã®StandardScalerã‚’ç”¨æ„
    scalers: dict[str, StandardScaler] = {}
    for col in col_list:
        # æœ€åˆã«ãã®colã«ã€ŒNoneã§ãªã„ã€å€¤ãŒå«ã¾ã‚Œã‚‹dfã‚’æ¢ã™
        for df in dfs:
            if col in df.columns:
                # print(f"col: {col}, df.select(pl.col(col).is_not_null().len()).item(): {df.select(pl.col(col).is_not_null().len()).item()}")
                if df.select(pl.col(col).is_not_null().sum()).item() > 0:
                    # å…¨éƒ¨NaNã®åˆ—ã‚’é™¤å¤–ã™ã‚‹
                    df = df.filter(pl.col(col).is_not_null())
                    # print(f"len(df): {len(df)}")
                    scaler = StandardScaler()
                    scaler.fit(df.select(col))
                    scalers[col] = scaler
                    if verbose:
                        print(f">>> '{col}' fitå…ƒ df ã®å…ˆé ­5è¡Œ:\n", df.select(col).head())
                    break
        else:
            raise ValueError(f"å…¨ã¦ã®DataFrameã«ãŠã„ã¦åˆ— '{col}' ã«æœ‰åŠ¹ãªå€¤ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

    # å„DataFrameã«å¯¾ã—ã¦æ¨™æº–åŒ–
    result_dfs = []
    for i, df in enumerate(dfs):
        df_scaled_cols = []
        for col in col_list:
            if col in df.columns:
                col_vals = df.select(col)
                transformed = scalers[col].transform(col_vals)
                col_df = pl.DataFrame(transformed, schema=[col], orient="row")
                col_df = col_df.fill_nan(None)  # â† NaNã‚’Polarsã®Noneã«
            else:
                col_df = pl.Series(name=col, values=[None] * df.height).to_frame()
            df_scaled_cols.append(col_df)

        df_scaled = pl.concat(df_scaled_cols, how="horizontal")
        df_rest = df.drop(col_list)
        df_final = df_rest.hstack(df_scaled)

        # è¡Œæ•°ãƒã‚§ãƒƒã‚¯
        assert df.shape[0] == df_final.shape[0], f"è¡Œæ•°ä¸ä¸€è‡´ at df {i}"

        if verbose:
            print(f"\n>>> df[{i}] æ¨™æº–åŒ–å¾Œã®å…ˆé ­5è¡Œ:\n", df_final.head())

        result_dfs.append(df_final)

    return result_dfs


"""
â˜…plot_venné–¢æ•°
"""
def plot_venn(
    df: pl.DataFrame,
    col_entity: str,
    col_category: str,
    category_order: list[str] | None = ['train', 'test', 'detail'],
    category_colors: dict[str, str] | None = {'train': 'royalblue', 'test': 'indianred', 'detail': 'gold'},
    subtitle_label_fontsize: int = 28,
    category_label_fontsize: int = 24,
    count_label_fontsize: int = 20,
    title: str = None,
    verbose: bool = False,
) -> alt.Chart:
    """
    Altairã§Vennå›³ï¼ˆé›†åˆã®é‡ãªã‚Šï¼‰ã‚’æç”»ã™ã‚‹é–¢æ•°ã€‚

    ä¸ãˆã‚‰ã‚ŒãŸ Polars DataFrame ã‚’åŸºã«ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆä¾‹: IDï¼‰ãŒã©ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆä¾‹: train/test/detailï¼‰ã«
    å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚å®Ÿéš›ã®æç”»ã¯ matplotlib ã‚’ç”¨ã„ã¦Vennå›³ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ç”»åƒã¨ã—ã¦ Altair ã«åŸ‹ã‚è¾¼ã‚€ã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    df : pl.DataFrame
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚`col_entity` ã¨ `col_category` åˆ—ã‚’å«ã‚€å¿…è¦ãŒã‚ã‚‹ã€‚

    col_entity : str
        é›†åˆå¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆä¾‹: IDï¼‰ã‚’ç¤ºã™åˆ—åã€‚

    col_category : str
        å„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒæ‰€å±ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªï¼ˆä¾‹: train, test, detailï¼‰ã‚’ç¤ºã™åˆ—åã€‚

    category_order : list[str] or None, optional
        Vennå›³ã«æç”»ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã®é †åºã€‚æœ€å¤§3ã‚«ãƒ†ã‚´ãƒªã¾ã§å¯¾å¿œã€‚

    category_colors : dict[str, str] or None, optional
        å„ã‚«ãƒ†ã‚´ãƒªã«å‰²ã‚Šå½“ã¦ã‚‹è‰²ï¼ˆmatplotlibã®ã‚«ãƒ©ãƒ¼åãªã©ï¼‰ã€‚

    subtitle_label_fontsize : int, optional (default=28)
        ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆé‡ãªã‚Šã®èª¬æ˜ï¼‰ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã€‚

    category_label_fontsize : int, optional (default=24)
        å„ã‚«ãƒ†ã‚´ãƒªåã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã€‚

    count_label_fontsize : int, optional (default=20)
        ã‚«ã‚¦ãƒ³ãƒˆï¼ˆé‡ãªã‚Šã®è¦ç´ æ•°ï¼‰ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã€‚

    title : str, optional
        ã‚°ãƒ©ãƒ•ã®ã‚¿ã‚¤ãƒˆãƒ«ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ `col_entity` ãŒä½¿ç”¨ã•ã‚Œã‚‹ã€‚

    verbose : bool, optional
        ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤
    -------
    alt.Chart
        Vennå›³ã‚’åŸ‹ã‚è¾¼ã‚“ã  Altair ã®ç”»åƒãƒãƒ£ãƒ¼ãƒˆã€‚

    ä½¿ç”¨ä¾‹
    -------
    ```python
    df_combined = pl.concat([
        df_train.with_columns(pl.lit("train").alias("src")).select(["PID", "src"]),
        df_test.with_columns(pl.lit("test").alias("src")).select(["PID", "src"]),
        df_detail.with_columns(pl.lit("detail").alias("src")).select(["PID", "src"]),
    ])
    plot_venn(df_combined, col_entity="PID", col_category="src")    
    ```

    ä½¿ç”¨ä¾‹2
    -------
    ```python
    def compare_id(
        df_train: pl.DataFrame,
        df_test: pl.DataFrame,
        df_detail: pl.DataFrame,
        col_compare: str,
        subtitle_label_fontsize: int = 18,
        category_label_fontsize: int = 16,
        count_label_fontsize: int = 12,
        width=600,
        height=200,
    ) -> alt.Chart:
        col_label = 'DataFrame'

        # å„DataFrameã«DataFrameåã‚’ç¤ºã™åˆ—ã‚’è¿½åŠ ã—ã€PIDã¨ãã®åˆ—ã ã‘ã‚’é¸æŠ
        df_train_labeled = df_train.with_columns(pl.lit("train").alias(col_label)).select([col_compare, col_label])
        df_test_labeled = df_test.with_columns(pl.lit("test").alias(col_label)).select([col_compare, col_label])
        df_detail_labeled = df_detail.with_columns(pl.lit("detail").alias(col_label)).select([col_compare, col_label])

        df_combined = pl.concat([df_train_labeled, df_test_labeled, df_detail_labeled], how="vertical")

        venn_chart = plot_venn(
            df=df_combined,
            col_entity=col_compare,
            col_category=col_label,
            subtitle_label_fontsize = subtitle_label_fontsize,
            category_label_fontsize = category_label_fontsize,
            count_label_fontsize = count_label_fontsize,
        ).properties(width=width, height=height)
        return venn_chart
    ```

    å‚™è€ƒ
    ----
    - matplotlib ã«ã‚ˆã‚‹æç”»ã‚’ Altair ã«åŸ‹ã‚è¾¼ã‚€ç‰¹æ®Šå‡¦ç†ã‚’è¡Œã£ã¦ã„ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®ç›´æ¥æç”»ã§ã¯ãªã„ã€‚
    - `_draw_venn_matplotlib_dual()` ã¨ `_matplotlib_to_altair()` ã«ä¾å­˜ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®è£œåŠ©é–¢æ•°ãŒå¿…è¦ã€‚
    - æœ€å¤§3ã‚«ãƒ†ã‚´ãƒªã¾ã§å¯¾å¿œï¼ˆmatplotlibã®Vennåˆ¶ç´„ã«ã‚ˆã‚‹ï¼‰ã€‚
    """
    if verbose:
        print(f"category_colors: {category_colors}")

    fig_matplotlib = _draw_venn_matplotlib_dual(
        df,
        col_entity=col_entity,
        col_category=col_category,
        category_order=category_order,
        category_colors=category_colors,
        subtitle_label_fontsize=subtitle_label_fontsize,
        category_label_fontsize=category_label_fontsize,
        count_label_fontsize=count_label_fontsize,
        verbose=verbose,
    )

    chart_altair = _matplotlib_to_altair(
        fig_matplotlib, 
        )
    if title is None:
        title = col_entity
    return chart_altair.properties(title=title)


def _draw_venn_matplotlib_dual(
    df: pl.DataFrame,
    col_entity: str,
    col_category: str,
    subtitle_label_fontsize: int,
    category_label_fontsize,
    count_label_fontsize,
    category_order: list[str] | None = ['train', 'test'],
    category_colors: dict[str, str] | None = None,
    figsize: tuple[int, int] = None, # (6, 10)
    verbose: bool = False,
) -> plt.Figure:
    """
    å…¨å€¤ã¨ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®Vennå›³ã‚’ä¸Šä¸‹ã«1æšã«ã¾ã¨ã‚ã¦æç”»ã—ã€Figureã‚’è¿”ã™ã€‚
    """
    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=figsize)

    _draw_venn_matplotlib(
        df=df,
        col_entity=col_entity,
        col_category=col_category,
        subtitle_label_fontsize=subtitle_label_fontsize,
        category_label_fontsize=category_label_fontsize,
        count_label_fontsize=count_label_fontsize,
        ax=ax1,
        use_unique=False,
        category_order=category_order,
        category_colors=category_colors,
        subtitle="all",
        verbose=verbose,
    )

    _draw_venn_matplotlib(
        df=df,
        col_entity=col_entity,
        col_category=col_category,
        subtitle_label_fontsize=subtitle_label_fontsize,
        category_label_fontsize=category_label_fontsize,
        count_label_fontsize=count_label_fontsize,
        ax=ax2,
        use_unique=True,
        category_order=category_order,
        category_colors=category_colors,
        subtitle="unique",
        verbose=verbose,
    )

    return fig


def _draw_venn_matplotlib(
    df: pl.DataFrame,
    col_entity: str,
    col_category: str | None,
    subtitle_label_fontsize: int,
    category_label_fontsize: int,
    count_label_fontsize: int,
    ax: plt.Axes,
    use_unique: bool = True,
    category_order: list[str] | None = ['train', 'test'],
    category_colors: dict[str, str] | None = None,
    subtitle: str = None,
    verbose: bool = False,
    offset_shared_area: float = 0.15,
) -> None:
    """
    æŒ‡å®šã—ãŸaxã«Vennå›³ã‚’æç”»ã™ã‚‹é–¢æ•°ã€‚
    use_unique=Trueãªã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤é›†åˆã€‚Falseãªã‚‰å¤šé‡é›†åˆã€‚
    subtitle ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã€ax.set_title ã§ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã‚‹ã€‚
    """
    from matplotlib_venn import venn2, venn3
    from collections import Counter


    # âœ… col_category ãŒ None ã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    # if (col_category is None) or (col_category not in df.columns):
    # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„ or None or å…¨éƒ¨ null ã®å ´åˆã¯ dummy ãƒ¢ãƒ¼ãƒ‰ã«
    if (
        col_category is None or
        col_category not in df.columns or
        df.select(pl.col(col_category).is_not_null().sum()).item() == 0
        ):
        dummy_col = "__dummy_category__"
        df = df.with_columns([
            pl.lit("").alias(dummy_col)
        ])
        col_category = dummy_col
        is_dummy_category = True  # â† ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
    else:
        is_dummy_category = False
        
    all_categories = df.select(pl.col(col_category)).unique().to_series().to_list()

    # category_order ã«åŸºã¥ãé¸æŠ
    if category_order is not None:
        ordered = [cat for cat in category_order if cat in all_categories]
        remaining = sorted(set(all_categories) - set(ordered))
        selected_categories = tuple(ordered + remaining)
    else:
        selected_categories = tuple(sorted(all_categories))

    if len(selected_categories) > 3:
        raise ValueError(f"ã‚«ãƒ†ã‚´ãƒªãŒ3ç¨®é¡ã‚’è¶…ãˆã¦ã„ã¾ã™: {selected_categories}")

    sets = []
    for cat in selected_categories:
        values = df.filter(pl.col(col_category) == cat).select(col_entity).to_series().to_list()
        sets.append(set(values) if use_unique else Counter(values))

    while len(sets) < 3:
        sets.append(set() if use_unique else Counter())
        selected_categories += ("",)

    # æç”»
    non_empty_count = sum(bool(s) for s in sets)
    if non_empty_count == 1:
        empty = Counter() if not use_unique else set()  # â† å‹ã‚’åˆã‚ã›ã‚‹
        venn = venn2(subsets=(sets[0], empty), set_labels=selected_categories[:2], ax=ax)
        venn_type = 2
    elif non_empty_count == 2:
        venn = venn2(subsets=sets[:2], set_labels=selected_categories[:2], ax=ax)
        venn_type = 2
    else:
        venn = venn3(subsets=sets, set_labels=selected_categories, ax=ax)
        venn_type = 3

    for label in venn.set_labels:
        if label:
            label.set_fontsize(category_label_fontsize)

    # fontsizeã‚’èª¿æ•´ã™ã‚‹
    # 1ã¤ã®å††ã‚’æããŸã‚ã«venn2ã‚’ä½¿ã£ã¦ã‚‹å ´åˆã€ãƒ€ãƒŸãƒ¼ã®å††ã®å€¤ã§ã‚ã‚‹0ãŒè¡¨ç¤ºã•ã‚Œã¦ã—ã¾ã†ã®ã§ç©ºæ–‡å­—ã«ã—ã¦æ¶ˆã™
    for id_, idx in venn.id2idx.items():
        if idx < len(venn.subset_labels):
            label = venn.subset_labels[idx]
            if label:
                if (
                    label.get_text() == "0"
                    and is_dummy_category
                    and id_ == '010'
                ):
                    label.set_text("")
                else:
                    label.set_fontsize(count_label_fontsize)
    
    # å…±é€šéƒ¨åˆ†ã®å€¤ãƒ†ã‚­ã‚¹ãƒˆãŒé‡ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒå¤šã„ã®ã§ä¸Šã«ãšã‚‰ã™
    # 2é ˜åŸŸã®é‡ãªã‚Šã¯1æ®µéšã€3é ˜åŸŸã®é‡ãªã‚Šã¯2æ®µéšä¸Šã«ãšã‚‰ã™
    if venn_type == 3:
        overlap_ids = ['110', '101', '011', '111']
    elif venn_type == 2:
        overlap_ids = ['11']  # 2é›†åˆã§é‡ãªã‚‹ã®ã¯1ã¤ã ã‘

    for vid in overlap_ids:
        try:
            label = venn.get_label_by_id(vid)
        except IndexError:
            label = None

        if label is not None:
            x, y = label.get_position()
            offset = offset_shared_area * 2 if vid == '111' else offset_shared_area
            label.set_position((x, y + offset))

    # ãƒ€ãƒŸãƒ¼ã‚«ãƒ†ã‚´ãƒªã§1ã¤ã®å††ãŒæã‹ã‚ŒãŸå ´åˆã€è‰²ã¯ã‚°ãƒ¬ãƒ¼ã«ã™ã‚‹
    if category_colors or is_dummy_category:
        id_map = ['100', '010', '001']
        for id_, cat in zip(id_map, selected_categories):
            idx = venn.id2idx.get(id_)
            if idx is not None and idx < len(venn.patches):
                patch = venn.patches[idx]
                if patch:
                    if is_dummy_category:
                        patch.set_color("lightgray")
                    elif category_colors and cat in category_colors:
                        patch.set_color(category_colors[cat])

    # ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«
    if subtitle:
        ax.set_title(subtitle, fontsize=subtitle_label_fontsize,
        )


def _matplotlib_to_altair(
    fig: plt.Figure,
) -> alt.Chart:
    """
    Matplotlibã®Figureã‚’Altairã®ç”»åƒãƒãƒ£ãƒ¼ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚
    """
    import base64
    from io import BytesIO


    buf = BytesIO()
    fig.tight_layout()
    fig.savefig(buf, format="png", bbox_inches="tight", transparent=True)
    plt.close(fig)
    buf.seek(0)
    encoded = base64.b64encode(buf.read()).decode("utf-8")
    image_url = "data:image/png;base64," + encoded

    return alt.Chart().mark_image(
        url=image_url,
    )


"""
â˜…profileé–¢æ•°
"""
def profile(
        *dfs,
        col_target=None,
        num_n_bins=10,
        width_chart=200,
        height_chart=200,
        str_col_bin_unique_limit: int = 100,
        standardize_line=True,
        normalize_histogram=True,
        tabulate_dfs_color: list[str] = ['lightblue', 'lightpink'],
        verbose=False,
        width_panel: int = 350,
        table_compact_fn=None,
        render_panel_fn=None,
    ):
    """
    è¤‡æ•°ã®DataFrameã‚’å¯¾è±¡ã«ã€å…¨åˆ—ã«å¯¾ã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯è¦–åŒ–ã¨ã‚µãƒãƒªè¡¨ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã€‚
    å„åˆ—ã«å¯¾ã—ã¦ã€Altairãƒãƒ£ãƒ¼ãƒˆï¼‹great_tablesè¡¨ã‚’æ¨ªä¸¦ã³ã«è¡¨ç¤ºã™ã‚‹ã€‚

    å„åˆ—ã«å¯¾ã—ã¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¾ãŸã¯æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã‚’æç”»ã—ã€æ¯”è¼ƒå¯èƒ½ãªå½¢å¼ã§è¡¨ç¤ºã€‚
    æ•°å€¤ãƒ»ã‚«ãƒ†ã‚´ãƒªãƒ»æ–‡å­—åˆ—ãªã©ã®å‹ã«å¿œã˜ã¦é©åˆ‡ãªãƒ“ãƒ‹ãƒ³ã‚°ã‚„æ¨™æº–åŒ–ãƒ»æ­£è¦åŒ–å‡¦ç†ã‚’è¡Œã†ã€‚
    ã¾ãŸã€å„DataFrameã«å¯¾ã™ã‚‹ `describe_ex()` ã®çµæœã‚’è‰²åˆ†ã‘ã—ã¦è¡¨å½¢å¼ã§è¡¨ç¤ºã€‚

    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    ----------
    *dfs : DataFrame(s)
        ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯¾è±¡ã¨ãªã‚‹ Polars ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆè¤‡æ•°å¯ï¼‰ã€‚

    col_target : str, optional
        æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹éš›ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ï¼ˆä¾‹ï¼šç›®çš„å¤‰æ•°ï¼‰ã€‚None ã®å ´åˆã¯çœç•¥ã€‚

    num_n_bins : int, optional (default=10)
        æ•°å€¤åˆ—ã®ãƒ“ãƒ³æ•°ã€‚ãƒ“ãƒ‹ãƒ³ã‚°ã¯ `_draw_profile_graph()` å†…éƒ¨ã§è‡ªå‹•å‡¦ç†ã•ã‚Œã‚‹ã€‚

    width_chart : int, optional
        å„ãƒãƒ£ãƒ¼ãƒˆã®æ¨ªå¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰ã€‚

    height_chart : int, optional
        å„ãƒãƒ£ãƒ¼ãƒˆã®é«˜ã•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰ã€‚

    columns_concat_chart : int, optional
        è¡¨ç¤ºæ™‚ã«1è¡Œã«ä¸¦ã¹ã‚‹ãƒãƒ£ãƒ¼ãƒˆã®æ•°ï¼ˆAltairã® `alt.concat(..., columns=...)` ã«å¯¾å¿œï¼‰ã€‚

    str_col_bin_unique_limit : int, optional (default=100)
        æ–‡å­—åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ—ã§è¡¨ç¤ºã™ã‚‹ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã®æœ€å¤§æ•°ã€‚è¶…ãˆã‚‹ã¨ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ã€‚

    standardize_line : bool, optional (default=True)
        æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã‚’æ¨™æº–åŒ–ï¼ˆå¹³å‡0, åˆ†æ•£1ï¼‰ã—ã¦æ¯”è¼ƒã™ã‚‹ã‹ã©ã†ã‹ã€‚

    normalize_histogram : bool, optional (default=True)
        ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’æ­£è¦åŒ–ï¼ˆç›¸å¯¾é »åº¦ï¼‰ã™ã‚‹ã‹ã©ã†ã‹ã€‚

    tabulate_dfs_color : list[str], optional
        `describe_ex()` ã®å‡ºåŠ›ã«å¯¾ã—ã¦è‰²ã‚’ä»˜ã‘ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆã€‚DataFrameã®é †ç•ªã«å¯¾å¿œã€‚

    verbose : bool, optional
        ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤
    -------
    None
        Altair ãƒãƒ£ãƒ¼ãƒˆãŠã‚ˆã³ HTML ãƒ†ãƒ¼ãƒ–ãƒ«ãŒ notebook ä¸Šã§ `display()` ã«ã‚ˆã£ã¦è¡¨ç¤ºã•ã‚Œã‚‹ã€‚

    ä½¿ç”¨ä¾‹
    -------
    >>> profile(df_train, df_test, col_target="target")

    å‚™è€ƒ
    ----
    - ãƒãƒ£ãƒ¼ãƒˆã¯ Altair ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€Jupyter Notebook / JupyterLab ä¸Šã§ã®å¯è¦–åŒ–ã‚’æƒ³å®šã€‚
    - `_draw_profile_graph()` ã‚„ `_draw_profile_table()` ãªã©ã®è£œåŠ©é–¢æ•°ã«ä¾å­˜ã€‚
    - `describe_ex()` ã‚’ä½¿ã£ã¦æ‹¡å¼µã‚µãƒãƒªã‚’ç”Ÿæˆã—ã¦ãŠã‚Šã€å‹ã‚„æ¬ æã€æœ€é »å€¤ãªã©ã‚‚è¡¨ã§ç¢ºèªå¯èƒ½ã€‚
    """
    from IPython.display import display
    from tqdm import tqdm

    columns = _get_ordered_unique_columns(dfs)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒãƒ«æç”»é–¢æ•°ï¼ˆchart + GT ã‚’æ¨ªä¸¦ã³ã«è¡¨ç¤ºï¼‰
    if render_panel_fn is None:
        def render_panel_fn(chart, gt):
            import io
            import base64
            from IPython.display import HTML

            buf = io.BytesIO()
            chart.save(fp=buf, format="png")
            buf.seek(0)
            chart_base64 = base64.b64encode(buf.read()).decode("utf-8")
            # GTã®ä¸Šéƒ¨ãƒãƒ¼ã‚¸ãƒ³ã«åˆã‚ã›ã¦å°‘ã—ãƒãƒ¼ã‚¸ãƒ³ã‚’å–ã‚‹
            chart_img_html = f'<img src="data:image/png;base64,{chart_base64}" style="max-width: 100%; margin-top: 10px;">'

            html = f"""
            <div style="display: flex; justify-content: flex-start; gap: 20px; margin-bottom: 0px; align-items: flex-start;">
                <div style="min-width: {width_panel}px; max-width: 500px; overflow-x: auto;">
                    {gt._repr_html_()}
                </div>
                <div style="width: {width_panel}px; text-align: left;">
                    {chart_img_html}
                </div>
            </div>
            """

            display(HTML(html))

    # å„åˆ—ã”ã¨ã«ã‚°ãƒ©ãƒ•ï¼‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œã£ã¦è¡¨ç¤º
    # pbar = tqdm(columns, desc="Profiling Columns", leave=False)
    # for col in pbar:
    for i, col in enumerate(columns, 1):
        # pbar.set_description(f"Processing... (col: {col})")
        # display(Markdown(f"### ğŸ“Š [{i}/{len(columns)}] {col}"))
        icon = _get_dtype_icon(dfs[0], col)
        display(Markdown(f"### {icon} `{col}` _(Column {i} of {len(columns)})_"))

        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        chart = _draw_profile_graph(
            *dfs, col=col, col_target=col_target, num_n_bins=num_n_bins,
            str_col_bin_unique_limit=str_col_bin_unique_limit,
            standardize_line=standardize_line,
            normalize_histogram=normalize_histogram,
            verbose=verbose
        )

        if chart is None:
            continue

        # describeãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        # dfs_describe = [df.select(col).describe_ex() for df in dfs]
        dfs_describe = []
        for df in dfs:
            if col in df.columns:
                dfs_describe.append(df.select(col).describe_ex())
        table = _draw_profile_table(*dfs_describe, dfs_color=tabulate_dfs_color)

        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ compact è¡¨ç¤ºé©ç”¨
        if table_compact_fn is not None:
            table = table_compact_fn(table)

        # è¡¨ã¨ã‚°ãƒ©ãƒ•ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        render_panel_fn(chart.properties(width=width_chart, height=height_chart), table)


def _get_dtype_icon(df: pl.DataFrame, col: str) -> str:
    dtype = df.schema[col]
    if dtype == pl.Int64 or dtype == pl.Int32 or dtype == pl.Float64 or dtype == pl.Float32:
        return "ğŸ”Ÿ"  # æ•°å€¤
    elif dtype == pl.Utf8:
        return "ğŸ†"  # æ–‡å­—åˆ—
    elif dtype == pl.Boolean:
        return "âœ…"  # çœŸå½å€¤
    elif dtype == pl.Datetime:
        return "ğŸ•’"  # æ—¥æ™‚
    elif dtype == pl.Date:
        return "ğŸ“…"  # æ—¥æ™‚
    elif dtype == pl.Timedelta:
        return "âŒ›"  # æ—¥æ™‚
    else:
        return "â“"  # ä¸æ˜å‹


def _draw_profile_graph(
    *dfs:pl.DataFrame,
    col:str,
    col_target: Optional[Union[str, list[str]]] = None, # Union[str, list[str]],
    dfs_name:list[str] = ['train', 'test'],
    dfs_color_histogram:list[str] = ['royalblue', 'indianred'],
    dfs_color_line:list[str] = ['blues', 'reds'],
    col_dataframe_name = 'DataFrame',
    col_target_unpivot_name: str = 'column',
    col_target_unpivot_value: str = 'target',
    normalize_histogram:bool = True,
    standardize_line:bool = True,
    num_n_bins: int = 10,
    dt_truncate_unit: str = "1mo",
    str_col_bin_unique_limit:int = 100,
    verbose:bool=False,
):
    """
    - profileé–¢æ•°(ã‚°ãƒ©ãƒ•ï¼‹è¡¨ã‚’å…¨åˆ—åˆ†è¡¨ç¤º)ã®ã‚°ãƒ©ãƒ•æç”»å‡¦ç†
    - plot_histogram, plot_line_point_over_bin, plot_venné–¢æ•°ãªã©ã‚’ä½¿ã†
    """
    from typing import Union, Optional


    assert len(dfs_name) >= len(dfs), f"dfs_nameã®è¦ç´ æ•°ãŒè¶³ã‚Šã¾ã›ã‚“ (å¿…è¦æ•°: {len(dfs)})"
    assert len(dfs_color_histogram) >= len(dfs), f"dfs_color_histogramã®è¦ç´ æ•°ãŒè¶³ã‚Šã¾ã›ã‚“ (å¿…è¦æ•°: {len(dfs)})"
    assert len(dfs_color_line) >= len(dfs), f"dfs_color_lineã®è¦ç´ æ•°ãŒè¶³ã‚Šã¾ã›ã‚“ (å¿…è¦æ•°: {len(dfs)})"

    # dfsãŒå˜å“ã‹ã¤dfsãŒãƒ¡ãƒ³ãƒ†ã•ã‚Œã¦ãªã•ãã†ãªå ´åˆã€DataFrameã®åå‰ã‚’æ¶ˆã™
    if len(dfs) == 1 and len(dfs_name) > 1:
        dfs_name = [None] 

    # col_targetã¯str, list[str]ã©ã£ã¡ã§ã‚‚ã„ã‘ã‚‹ã‚ˆã†ã«ã™ã‚‹(å†…éƒ¨ã§ã¯listã§çµ±ä¸€)
    # col_target_list = [col_target] if isinstance(col_target, str) else col_target
    if col_target is None:
        col_target_list = []
    elif isinstance(col_target, str):
        col_target_list = [col_target]
    else:
        col_target_list = col_target

    # åˆ—å: DataFrame, å€¤: train, testã¿ãŸã„ãªåˆ—ã‚’è¿½åŠ ã™ã‚‹(è‰²åˆ†ã‘ç”¨)
    dfs = [
        df.with_columns(pl.lit(name).alias(col_dataframe_name))
        for df, name in zip(dfs, dfs_name)
    ]

    # åˆ—ã‚’æƒãˆã‚‹(ãªã„å ´åˆã¯å€¤ãŒã™ã¹ã¦Nullã®åˆ—ã¨ãªã‚‹)
    dfs_aligned = _align_all_columns(*dfs)

    # binåˆ—ã‚’ä½œã‚‹(æœªçµåˆ)
    *dfs_bin, df_bin_detail_info = get_bin_column(
        *dfs_aligned, col=col, 
        num_n_bins=num_n_bins, dt_truncate_unit=dt_truncate_unit, verbose=False
    )
    col_bin = dfs_bin[0].to_series().name

    # â†“ã“ã‚Œã¯å‘¼ã³å‡ºã™å´ã«ã‚‚ã£ã¦ã„ãã‹ã‚‚â˜…

    # ã‚«ãƒ†ã‚´ãƒªåˆ—ã®ã‚¯ãƒ©ã‚¹ãŒåˆ¶é™ä»¥ä¸Šãªã‚‰æç”»ã—ãªã„(ãã®binåˆ—ã¯ã™ã¹ã¦Nullã¨ã™ã‚‹â†’æç”»ã•ã‚Œãªã„)
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ã‚’ç¢ºèª
    n_uniques = [
        df_bin.select(pl.col(col_bin).n_unique()).item()
        for df_bin in dfs_bin
    ]
    # binæ•°ã®æœ€å¤§å€¤ã‚’å–ã‚‹
    n_unique_max = max(n_uniques)
    # ãƒã‚§ãƒƒã‚¯NGãƒ•ãƒ©ã‚°
    col_bin_check_ng = n_unique_max > str_col_bin_unique_limit


    # NG(ã‚¯ãƒ©ã‚¹æ•°å¤šã™ã)ãªã‚‰ã‚¹ã‚­ãƒƒãƒ— â‡’ ãƒ™ãƒ³å›³
    if col_bin_check_ng:
        # print(f"åˆ—: {col} ã®binæ•°ãŒå¤šã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (binæ•°: {n_unique_max}, ä¸Šé™: {str_col_bin_unique_limit})")
        # return None
        if verbose:
            print(f"åˆ—: {col} ã®binæ•°ãŒå¤šã™ãã‚‹ãŸã‚ãƒ™ãƒ³å›³ã‚’æç”»ã—ã¾ã™ (binæ•°: {n_unique_max}, ä¸Šé™: {str_col_bin_unique_limit})")
        
        # çµåˆã—ã¦plot_vennã«æ¸¡ã™
        dfs_labeled = [
            df.select([col, col_dataframe_name])
            for df in dfs
        ]
        df_combined = pl.concat(dfs_labeled, how="vertical")
        category_colors = dict(zip(dfs_name, dfs_color_histogram))
        venn_chart = plot_venn(
            df=df_combined,
            col_entity=col,
            col_category=col_dataframe_name,
            # width=width,
            # height=height,
            category_colors=category_colors,
            title=f"{col}",
            verbose=verbose,
        )
        return venn_chart


    # # binåˆ—ã‚’çµåˆã™ã‚‹
    if col_bin != col:
        dfs_with_bin = [
            df_aligned.hstack(df_bin)
            for df_aligned, df_bin in zip(dfs_aligned, dfs_bin)
        ]
    else:
        dfs_with_bin = dfs_aligned

    # æ¨™æº–åŒ–ã™ã‚‹(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    if standardize_line and col_target_list:
        dfs_with_bin = _standardize_columns_by_first_df(
            *dfs_with_bin, col_list=col_target_list
        )

    # ---- ã‚µãƒ–é–¢æ•°ï¼ˆãƒ«ãƒ¼ãƒ—ã®å‰ã«ç½®ãï¼‰ ----
    # domain = dfs_name
    # range = dfs_color_histogram
    def create_histogram_chart(df_with_bin: pl.DataFrame):
        # color_scale_bar = alt.Scale(domain=['train', 'test'], range=['royalblue', 'indianred'])
        color_scale_bar = alt.Scale(domain=dfs_name, range=dfs_color_histogram)

        chart_histogram = plot_histogram(
            df_with_bin,
            col_bin=col_bin,
            col_color=col_dataframe_name,
            df_bin_detail_info=df_bin_detail_info,
            normalize_histogram=normalize_histogram,
            verbose=False
        )
        is_all_name_missing = df_with_bin.select(pl.col(col_dataframe_name).is_null().all()).item()
        if is_all_name_missing:
            legend = None
        else:
            legend = alt.Legend(title=f'{col_dataframe_name}')
        chart_histogram = chart_histogram.encode(
            color=alt.Color(
                f"{col_dataframe_name}:N",
                scale=color_scale_bar,
                legend=legend
            )
        )
        return chart_histogram#, train_or_test

    name_to_color_line = dict(zip(dfs_name, dfs_color_line))
    def create_line_point_chart(df_with_bin: pl.DataFrame):
        dataframe_name = df_with_bin.select(col_dataframe_name).unique().item()
        # color_scale_scheme_line = 'blues' if dataframe_name == 'train' else 'reds'
        color_scale_scheme_line = name_to_color_line[dataframe_name]

        # targetåˆ—ãŒè¤‡æ•°ã§ã‚‚ã„ã‘ã‚‹ã‚ˆã†ã«ã€unpivot(melt)ã—ã¦ãƒ­ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ç›´ã™
        df_unpivot_target = df_with_bin.unpivot(
            on=col_target_list,
            index=col_bin,
            variable_name=col_target_unpivot_name,
            value_name=col_target_unpivot_value
        )

        chart_line_point = plot_line_point_over_bin(
            df_unpivot_target,
            col_bin=col_bin,
            col_target=col_target_unpivot_value,
            col_color=col_target_unpivot_name,
            df_bin_detail_info=df_bin_detail_info,
            color_scale_scheme=color_scale_scheme_line,
            verbose=False
        )

        # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ãŒ1ã¤ã‚‚ãªã„å ´åˆã€æŠ˜ã‚Œç·šç”¨ã®ãƒ¬ã‚¸ã‚§ãƒ³ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«(å‡¡ä¾‹ã®ã‚°ãƒ«ãƒ¼ãƒ—å)ã‚’è¡¨ç¤ºã—ãªã„
        is_all_target_missing = df_unpivot_target.select(pl.col(col_target_unpivot_value).is_null().all()).item()
        if is_all_target_missing:
            legend = None
        else:
            legend = alt.Legend(title=f"target{f' ({dataframe_name})' if dataframe_name else ''}")

        chart_line_point = chart_line_point.encode(
            color=alt.Color(legend=legend)
        )
        return chart_line_point

    # ---- ã“ã“ã‹ã‚‰ãƒ«ãƒ¼ãƒ—æœ¬ä½“ ----
    chart_histogram_list = []
    chart_line_point_list = []

    for df_with_bin in dfs_with_bin:
        is_all_histogram_bin_missing = df_with_bin.select(pl.col(col_bin).is_null().all()).item()
        if is_all_histogram_bin_missing:
            continue

        chart_histogram = create_histogram_chart(df_with_bin)
        chart_histogram_list.append(chart_histogram)

        if col_target_list:
            chart_line_point = create_line_point_chart(df_with_bin)
            chart_line_point_list.append(chart_line_point)

    # ---- æœ€å¾Œã«ã¾ã¨ã‚ã‚‹ ----
    chart_histogram = alt.layer(*chart_histogram_list)

    if col_target_list:
        chart_line_point = alt.layer(*chart_line_point_list)
        chart = alt.layer(chart_histogram, chart_line_point).resolve_scale(
            y='independent', color='independent', shape='independent'
        )
    else:
        chart = chart_histogram

    return chart


def _draw_profile_table(
    *dfs: pl.DataFrame,
    dfs_name: list[str] = ['train', 'test'],
    dfs_color: list[str] = ['lightblue', 'lightpink'],
    use_dark_theme: bool = True,
    use_compact_style: bool = True,
    label_columns: list[str] | None = ['statistic'],
    sig_digits: int | None = 3,
    show_dtype_row: bool = False  # â† è¿½åŠ 
):
    """
    è¤‡æ•°ã® Polars DataFrame ã‚’æ¯”è¼ƒã—ã‚„ã™ã„è¡¨å½¢å¼ã«æ•´å½¢ã—ã¦è¿”ã™ã€‚
    å‹æƒ…å ±è¡Œã¨è¦–è¦šçš„ãªã‚¹ã‚¿ã‚¤ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã€‚
    """
    from IPython.display import HTML
    from great_tables import GT, style, loc, px


    num_dfs = len(dfs)
    assert num_dfs >= 1, "1ã¤ä»¥ä¸Šã®DataFrameãŒå¿…è¦ã§ã™"

    if dfs_name is None:
        dfs_name = [f"df{i+1}" for i in range(num_dfs)]
    if dfs_color is None:
        dfs_color = ["lightgray"] * num_dfs

    dfs_name = dfs_name[:num_dfs]
    dfs_color = dfs_color[:num_dfs]
    label_columns = label_columns or []

    # ãƒ©ãƒ™ãƒ«åˆ—ã®å‡¦ç†
    if label_columns:
        for col in label_columns:
            for df in dfs:
                assert col in df.columns, f"{col} ãŒå…¨ã¦ã®DataFrameã«å¿…è¦ã§ã™"
        label_df = dfs[0].select(label_columns)
        dfs_raw = tuple(df.drop(label_columns) for df in dfs)
    else:
        label_df = None
        dfs_raw = dfs

    schema_info = [df.schema for df in dfs_raw]
    label_schema = dfs[0].schema if label_columns else {}

    # sig_digits ã®é©ç”¨
    if sig_digits is not None:
        dfs = tuple(
            df.with_columns([
                pl.col(col).map_elements(lambda x: _format_sig(x, sig_digits), return_dtype=pl.String).alias(col)
                for col in df.columns
            ]) for df in dfs_raw
        )
    else:
        dfs = dfs_raw

    # ã‚«ãƒ©ãƒ åã« dfå ã‚’è¿½åŠ 
    dfs_named = []
    column_to_color, column_to_df, column_to_full = {}, {}, {}

    for i, (df, name, color) in enumerate(zip(dfs, dfs_name, dfs_color)):
        renamed_cols = {}
        for col in df.columns:
            new_col = col if num_dfs == 1 else f"{col} ({name})"
            renamed_cols[col] = new_col
            column_to_color[new_col] = color
            column_to_df.setdefault(col, []).append(i)
            column_to_full.setdefault(col, []).append(new_col)
        dfs_named.append(df.rename(renamed_cols))

    df_combined = pl.concat(dfs_named, how="horizontal")

    if label_df is not None:
        df_combined = label_df.hstack(df_combined)
        if num_dfs > 1:
            df_combined = _reorder_columns_by_df_map(df_combined, label_columns, column_to_full, column_to_df)
    else:
        if num_dfs > 1:
            df_combined = _reorder_columns_by_df_map(df_combined, [], column_to_full, column_to_df)

    # å‹æƒ…å ±ã®1è¡Œç›®ã‚’è¿½åŠ 
    if show_dtype_row:
        dtype_row = {}
        for schema, name in zip(schema_info, dfs_name):
            for col in schema:
                full_col = col if num_dfs == 1 else f"{col} ({name})"
                dtype_row[full_col] = str(schema[col])
        for col in label_columns:
            dtype_row[col] = str(label_schema.get(col, ""))

        dtype_row_filled = {col: dtype_row.get(col, "") for col in df_combined.columns}
        df_combined = pl.concat([pl.DataFrame([dtype_row_filled]), df_combined], how="vertical")

    # GreatTables ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
    table = GT(df_combined)
    if use_dark_theme:
        table = table.tab_options(
            table_background_color="#1e1e1e",
            heading_background_color="#2e2e2e",
            row_group_background_color="#2e2e2e",
            table_border_top_color="#444444",
            table_border_bottom_color="#444444"
        )
    if use_compact_style:
        table = table.tab_options(
            data_row_padding=px(2),
            row_group_padding=px(2),
            heading_title_font_size="small",
            heading_subtitle_font_size="small",
            table_font_size="small"
        )
        table = table.opt_vertical_padding(scale=0.5)
        table = table.opt_horizontal_padding(scale=0.7)

    for col in df_combined.columns:
        if col in label_columns:
            continue
        color = column_to_color.get(col)
        if color:
            table = table.tab_style(style=style.text(color=color), locations=loc.body(columns=col))
            table = table.tab_style(style=style.text(color=color), locations=loc.column_labels(columns=col))

    if show_dtype_row:
        table = table.tab_style(style=style.borders(sides="top", color="#888", style="solid", weight="2px"), locations=loc.body(rows=[0]))
        table = table.tab_style(style=style.borders(sides="bottom", color="#888", style="solid", weight="2px"), locations=loc.body(rows=[0]))
        table = table.tab_style(style=style.text(color="#bbb", weight="bold"), locations=loc.body(rows=[0]))

    # return table
    # ä»–ã¨åˆã‚ã›ã‚‹ãŸã‚å·¦å¯„ã›ã«ã™ã‚‹
    table_html = HTML(f"""
        <div style="text-align: left; display: inline-block;">
        {table._repr_html_()}
        </div>
        """)
    return table_html


def _reorder_columns_by_df_map(
    df: pl.DataFrame,
    label_columns: list[str],
    column_to_full: dict[str, list[str]],
    column_to_df: dict[str, list[int]]
) -> pl.DataFrame:
    """
    å„ baseåˆ—ï¼ˆæ‹¬å¼§ã®å‰ï¼‰ã‚’ã€dfã®é †ã«æƒãˆã¦äº¤äº’ã«ä¸¦ã¹ã‚‹ã€‚
    label_columns ã¯ãã®ã¾ã¾å…ˆé ­ã«ç¶­æŒã€‚

    ä¾‹ï¼š
        df1: x, y   df2: x  â†’ x (train), x (test), y (train)
    """
    base_order = [base for base in column_to_full if any(col in df.columns for col in column_to_full[base])]
    ordered_cols = label_columns[:]
    for base in base_order:
        for idx in column_to_df[base]:
            if idx < len(column_to_full[base]):
                col = column_to_full[base][idx]
                if col in df.columns:
                    ordered_cols.append(col)
    return df.select(ordered_cols)


def _get_ordered_unique_columns(dfs: Sequence[pl.DataFrame]) -> list[str]:
    seen = set()
    ordered_cols = []
    for df in dfs:
        for col in df.columns:
            if col not in seen:
                seen.add(col)
                ordered_cols.append(col)
    return ordered_cols


"""
__all__ ã‚’å‹•çš„ã«ç”Ÿæˆï¼ˆã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®é–¢æ•°ã ã‘ã‚’å¯¾è±¡ã«ã™ã‚‹ï¼‰
"""
__all__ = [
    name for name, val in globals().items()
    if (
        (isinstance(val, types.FunctionType) or isinstance(val, type))  # é–¢æ•° or ã‚¯ãƒ©ã‚¹
        and 
        val.__module__ == __name__  # ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®ã‚‚ã®ã«é™å®š
    )
]